{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc463cd-ac20-4d25-8a35-3dc86f009e8a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting PGVector\n",
      "  Downloading pgvector-0.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting langchain_aws\n",
      "  Downloading langchain_aws-0.2.21-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
      "  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.32-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from langchain) (2.11.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from langchain) (2.32.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from langchain_community) (3.11.16)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain_community)\n",
      "  Downloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: boto3>=1.37.24 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from langchain_aws) (1.37.28)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.28 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from boto3>=1.37.24->langchain_aws) (1.37.28)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from boto3>=1.37.24->langchain_aws) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from boto3>=1.37.24->langchain_aws) (0.11.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.51->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from botocore<1.38.0,>=1.37.28->boto3>=1.37.24->langchain_aws) (2.9.0.post0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.28->boto3>=1.37.24->langchain_aws) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pgvector-0.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading langchain_aws-0.2.21-py3-none-any.whl (119 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.32-py3-none-any.whl (358 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m147.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m147.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading greenlet-3.2.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (580 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m580.6/580.6 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading orjson-3.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, python-dotenv, orjson, numpy, mypy-extensions, marshmallow, jsonpatch, httpx-sse, greenlet, typing-inspect, SQLAlchemy, requests-toolbelt, PGVector, pydantic-settings, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain_aws, langchain, langchain_community\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "graph-notebook 4.6.2 requires numpy<1.24.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PGVector-0.4.0 SQLAlchemy-2.0.40 dataclasses-json-0.6.7 greenlet-3.2.0 httpx-sse-0.4.0 jsonpatch-1.33 langchain-0.3.23 langchain-core-0.3.54 langchain-text-splitters-0.3.8 langchain_aws-0.2.21 langchain_community-0.3.21 langsmith-0.3.32 marshmallow-3.26.1 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.16 pydantic-settings-2.9.1 python-dotenv-1.1.0 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain_community PGVector langchain_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aadd3e1-d07d-43a7-b708-7264e5b0fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install boto3 pandas psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65493874-7f25-4fdf-b80b-d625b1c4119e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_aws import ChatBedrock\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8645136-2efa-4e2b-8966-ad8e4cb6a21d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# Instantiate loader\n",
    "loader = CSVLoader(\n",
    "    file_path=\"Cleaned_Students_Performance.csv\",\n",
    "    csv_args={\"delimiter\": \",\", \"quotechar\": '\"'},\n",
    "    content_columns=[]  # default: all non-metadata columns\n",
    ")\n",
    "\n",
    "# Load rows as Documents\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18161d46-2eeb-4511-a5ae-f03d5efc78f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,      # max characters per chunk\n",
    "    chunk_overlap=100     # overlapping chars between chunks\n",
    ")\n",
    "\n",
    "# Split loaded documents into finer chunks\n",
    "chunks = splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721a510c-7a18-4945-ac85-3fa9c05ebcc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cred(db):\n",
    "    return PGVector.connection_string_from_db_params(driver='psycopg2',\n",
    "    user='cymonixadmin',\n",
    "    password='cymonix123',\n",
    "    host='preprod-rag-cymonixiq-db02.czmj15zygnmm.us-west-2.rds.amazonaws.com',\n",
    "    port='5432',\n",
    "    database= db,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e4a1b43-6c00-4cf0-86a8-ae40a862fcad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/langchain_community/vectorstores/pgvector.py:488: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  store = cls(\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def ingest_csv_to_aurora(db_key: str, collection_name: str, csv_path: str):\n",
    "    # 1. Load & chunk:\n",
    "    loader = CSVLoader(file_path=csv_path)\n",
    "    docs = loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    # 2. Initialize Bedrock embeddings:\n",
    "    embeddings = BedrockEmbeddings()\n",
    "\n",
    "    # 3. Connection string (SQLAlchemy URI to Aurora Postgres):\n",
    "    connection = cred(db_key)  # e.g., \"postgresql+psycopg://user:pass@host:5432/dbname\"\n",
    "    # 4. Create & populate PGVector store:\n",
    "    store = PGVector.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        connection_string=connection,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "\n",
    "    return store\n",
    "\n",
    "# Example usage:\n",
    "vector_store = ingest_csv_to_aurora(\n",
    "    db_key=\"vec-db\",\n",
    "    collection_name=\"my_csv_chunks\",\n",
    "    csv_path=\"Cleaned_Students_Performance.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fccdff1-29dc-477c-b1a3-5e8ec99b8b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_db_inst(database, collection_name):\n",
    "# Initialize the text embedding model\n",
    "    embeddings = BedrockEmbeddings()\n",
    "    db = database\n",
    "    CONNECTION_STRING = cred(db)\n",
    "# Create a vector database store instance and populate it with document data and embeddings\n",
    "    return PGVector.from_existing_index(\n",
    "            embedding=embeddings,\n",
    "            collection_name=collection_name,\n",
    "            connection_string=CONNECTION_STRING\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c47f0a7-e4fd-44cc-92ff-ee12c67a7061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/langchain_community/vectorstores/pgvector.py:1092: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  store = cls(\n"
     ]
    }
   ],
   "source": [
    "db_key=\"vec-db\"\n",
    "collection_name=\"my_csv_chunks\"\n",
    "db1 = create_db_inst(db_key, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02dfa87a-63f5-4368-ac86-60923f4dbcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"give me unique of race ethnicity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7255b430-9128-4440-92e5-a60abec72a58",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-6847cd6417c8>:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  matched_docs = retriever.get_relevant_documents(query=question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " page_content='gender: 1\n",
      "race_ethnicity: group E\n",
      "parental_level_of_education: bachelor's degree\n",
      "lunch: 1\n",
      "test_preparation_course: 1\n",
      "math_score: 100\n",
      "reading_score: 100\n",
      "writing_score: 100\n",
      "total_score: 300\n",
      "average_score: 100.0' metadata={'source': 'Cleaned_Students_Performance.csv', 'row': 916}\n",
      "\n",
      " page_content='gender: 1\n",
      "race_ethnicity: group C\n",
      "parental_level_of_education: some college\n",
      "lunch: 1\n",
      "test_preparation_course: 0\n",
      "math_score: 63\n",
      "reading_score: 63\n",
      "writing_score: 60\n",
      "total_score: 186\n",
      "average_score: 62.0' metadata={'source': 'Cleaned_Students_Performance.csv', 'row': 967}\n",
      "\n",
      " page_content='gender: 1\n",
      "race_ethnicity: group A\n",
      "parental_level_of_education: some college\n",
      "lunch: 1\n",
      "test_preparation_course: 1\n",
      "math_score: 100\n",
      "reading_score: 96\n",
      "writing_score: 86\n",
      "total_score: 282\n",
      "average_score: 94.0' metadata={'source': 'Cleaned_Students_Performance.csv', 'row': 623}\n",
      "\n",
      " page_content='gender: 1\n",
      "race_ethnicity: group D\n",
      "parental_level_of_education: some high school\n",
      "lunch: 1\n",
      "test_preparation_course: 0\n",
      "math_score: 81\n",
      "reading_score: 78\n",
      "writing_score: 78\n",
      "total_score: 237\n",
      "average_score: 79.0' metadata={'source': 'Cleaned_Students_Performance.csv', 'row': 981}\n",
      "\n",
      " page_content='gender: 1\n",
      "race_ethnicity: group B\n",
      "parental_level_of_education: some college\n",
      "lunch: 1\n",
      "test_preparation_course: 0\n",
      "math_score: 58\n",
      "reading_score: 50\n",
      "writing_score: 45\n",
      "total_score: 153\n",
      "average_score: 51.0' metadata={'source': 'Cleaned_Students_Performance.csv', 'row': 834}\n",
      "\n",
      " page_content='gender: 1\n",
      "race_ethnicity: group E\n",
      "parental_level_of_education: some college\n",
      "lunch: 1\n",
      "test_preparation_course: 1\n",
      "math_score: 99\n",
      "reading_score: 87\n",
      "writing_score: 81\n",
      "total_score: 267\n",
      "average_score: 89.0' metadata={'source': 'Cleaned_Students_Performance.csv', 'row': 306}\n",
      "\n",
      " page_content='gender: 0\n",
      "race_ethnicity: group B\n",
      "parental_level_of_education: some college\n",
      "lunch: 1\n",
      "test_preparation_course: 1\n",
      "math_score: 50\n",
      "reading_score: 64\n",
      "writing_score: 66\n",
      "total_score: 180\n",
      "average_score: 60.0' metadata={'source': 'Cleaned_Students_Performance.csv', 'row': 675}\n",
      "\n",
      " page_content='gender: 1\n",
      "race_ethnicity: group D\n",
      "parental_level_of_education: some college\n",
      "lunch: 1\n",
      "test_preparation_course: 0\n",
      "math_score: 40\n",
      "reading_score: 42\n",
      "writing_score: 38\n",
      "total_score: 120\n",
      "average_score: 40.0' metadata={'source': 'Cleaned_Students_Performance.csv', 'row': 33}\n",
      "\n",
      " page_content='gender: 1\n",
      "race_ethnicity: group B\n",
      "parental_level_of_education: some high school\n",
      "lunch: 1\n",
      "test_preparation_course: 0\n",
      "math_score: 72\n",
      "reading_score: 68\n",
      "writing_score: 67\n",
      "total_score: 207\n",
      "average_score: 69.0' metadata={'source': 'Cleaned_Students_Performance.csv', 'row': 126}\n",
      "\n",
      " page_content='gender: 1\n",
      "race_ethnicity: group E\n",
      "parental_level_of_education: some high school\n",
      "lunch: 1\n",
      "test_preparation_course: 0\n",
      "math_score: 30\n",
      "reading_score: 26\n",
      "writing_score: 22\n",
      "total_score: 78\n",
      "average_score: 26.0' metadata={'source': 'Cleaned_Students_Performance.csv', 'row': 76}\n"
     ]
    }
   ],
   "source": [
    "retriever = db1.as_retriever(search_type=\"mmr\", search_kwargs={'k': 10, 'lambda_mult': 0.5})\n",
    "matched_docs = retriever.get_relevant_documents(query=question)\n",
    "for doc in matched_docs:\n",
    "    print(f\"\\n {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0eb9157-fa13-419c-94af-1eb5a5e59c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(db, question):\n",
    "    # Initialize the Bedrock client using boto3\n",
    "    client = boto3.client(service_name=\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "    # Read and update the prompt with the job_id\n",
    "    with open('prompt.txt', 'r') as file:\n",
    "        prompt = file.read()\n",
    "        \n",
    "    # Initialize the BedrockChat LLM using LangChain's BedrockChat class\n",
    "    llm = ChatBedrock(\n",
    "        client=client,\n",
    "        model_id= \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        beta_use_converse_api=True,\n",
    "        streaming=True\n",
    "    )\n",
    "    prompt_template = PromptTemplate(\n",
    "        template=prompt,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    # Set up the retrieval chain with the language model and database retriever\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt_template},\n",
    "        retriever=db.as_retriever(search_type=\"mmr\", search_kwargs={'k': 9, 'lambda_mult': 0.5}),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "672afbad-e80e-4ccf-8936-d92bc5182d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is the average score of group b race ethnicity and parental level education in some college and math score is 88\"\n",
    "chain1 = create_chain(db1, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f2b4300-9172-4117-aec6-9df866e5ca18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 133 ms, sys: 46.2 ms, total: 179 ms\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import re\n",
    "response = chain1.invoke(question)\n",
    "result = response['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "070255d4-3752-4214-8dad-ffdfddadf394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at the data provided, there is no student with race_ethnicity \"group B\", parental_level_of_education \"some college\", and math_score exactly 88. The question asks for the average score of students meeting these specific criteria, but none of the records in the context match these exact specifications. The dataset only shows students from group B with associate's degree, bachelor's degree, or master's degree as their parental education levels, and none have a math score of exactly 88.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ebfee9-ed3f-4b67-8235-bf6e313d3a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b0932-0fb5-4c07-88c6-9bbf6d4a23e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b97ca3-983a-4125-bd07-453858e0ee2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a704d0-d086-40c5-a35b-7f786848e443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce6689-99a1-4c40-8222-5246ce8a1ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3419bec-c640-4c9a-9292-641918e70b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b8d69-00b7-493e-a511-c0e6ccbbf353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9312d3b-b541-411e-a80d-0e32f82ef2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32dd71f-ba24-4c59-bba4-872717b277f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e74009c-3a8b-430e-b5e9-8e5d62c0af4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7aac0a-6194-42b9-9416-9e4c740905e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6ab9b-3c06-4250-8c11-22131fd5bfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77685eb-40d9-48ae-9096-1a902a437024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c67260-1c57-49fe-a7c8-f12453073e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efee66-6358-4983-b569-5a7073a4d8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaee59f-6333-4462-9d47-2d8239740c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b6f89c-9a26-416e-8458-9b7fba25d73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20987946-10d5-4dde-8011-b2639d12c032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bcff16-c6c9-41e1-aa71-dcbb60747371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeeaf3a-7f56-47bc-8e48-b98163a79def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51439f51-6dd9-451b-9ad2-78435d0ce340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3d3e0-613f-4a8d-9d0d-f4bef883a81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94108693-cf18-44f3-b1bd-eeb76e25f6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6232ac6-7e69-44a5-905b-69ecfe29e2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9c77c-0566-4327-ad2d-994093146a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99598d6-f4a2-4ec1-b412-7800127950ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f43e8-424d-4839-875c-4b16919973eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87561c05-c6cf-45f4-8ac2-8376f276b0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
